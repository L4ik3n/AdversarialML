{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vulnerability analysis of popular CNN models to untargeted evasion attacks (FGSM, PGD, BIM, JSMA)"
      ],
      "metadata": {
        "id": "PxxO-5MFN0H-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install ART framwerok**"
      ],
      "metadata": {
        "id": "anjKG0E7KBG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAq14hLYKDcw",
        "outputId": "66663ec2-9ad0-41f9-8eeb-b9a5469a6dca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.20.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (75.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.6.0)\n",
            "Downloading adversarial_robustness_toolbox-1.20.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\n",
            "Successfully installed adversarial-robustness-toolbox-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install dependecies**"
      ],
      "metadata": {
        "id": "D9KF8at1KGct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent, BasicIterativeMethod, SaliencyMapMethod\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "from art.utils import load_dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "6iBYQE9KKHW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import data set and pretrained models**"
      ],
      "metadata": {
        "id": "Ve2yY11xKNVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset('cifar10')\n",
        "x_train = np.transpose(x_train, (0, 3, 1, 2)).astype(np.float32)\n",
        "x_test = np.transpose(x_test, (0, 3, 1, 2)).astype(np.float32)\n",
        "y_train = np.argmax(y_train, axis=1)\n",
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std = (0.2023, 0.1994, 0.201)\n",
        "\n",
        "test_models = {\n",
        "\n",
        "    'Resnet56': lambda: torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet56\", pretrained=True),\n",
        "    'VGG19': lambda: torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg19_bn\", pretrained=True),\n",
        "    'MobileNetV2': lambda: torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_mobilenetv2_x1_4\", pretrained=True),\n",
        "    'repvgg_a2': lambda: torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_repvgg_a2\", pretrained=True),\n",
        "}\n"
      ],
      "metadata": {
        "id": "bMFO-6B4Kaj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate effectivness**"
      ],
      "metadata": {
        "id": "QcijobjbK2vM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dfcdb1f9ad6e48bbbd93dac1e20b6632",
            "8c6d7a7df71f40cea7f23ef99d0a6041",
            "1dc985033b9640ce8227ee904effca71",
            "86eab892fbea407c80c2c6d880b4dd69",
            "c096de508d1b487b94d07364ffba0a30",
            "07395c1bc8d84944bc77c78150c0aff1",
            "2dd108d71bd3430e8eb475e219884bfd",
            "d74fa09ff14e4be2916c5287e12f2ef4",
            "a133f50073a3402f980daf951dcab342",
            "b4f8a12907a64a05b3a433378d03eeda",
            "bbe770326d19450aae73113b8c78aca7",
            "156b6822152d4ae6a98fcf354c78a0e0",
            "512c80e2b8b7442eae3cc7da35098e30",
            "63fe5ef7b2224952aa0e22572311bf9a",
            "83c4e4e16dd14699a94cabbe88c24d3e",
            "d23a2ad397404d449b532b843d3530e4",
            "3033560652fe469c9eb3da8aeb2988b5",
            "bf3819e0e8b84052b8c9ad5c7516459a",
            "f409246bf7424a5a9a3dd387db10a152",
            "facec4bb6ea94cc9b7c86f8dbbc07cdb",
            "19ad57694d634528baa9f47754ae8e4f",
            "3577e6773f35440385fc267f6f75b96b",
            "15e2064bbd29499a91b3e3f8af7d27f2",
            "54859a092cbc4fdab020ad62477784a9",
            "6fc8abb8a7bc490c988ad84a4ddbeb2e",
            "2a5215e817ad4cac84949f4aa6b355c9",
            "27721e07c26d4421b0e1fb2e190aff72",
            "9071bfaebd384811a5a459bd46f32689",
            "db6e319eac1e44d5becae2c0be9115d8",
            "b610df7372fb478ca3f12111c9660a5f",
            "7f511d9664e0429f97400aa52e1c816e",
            "64c22d67f0054004a33aed4619357b8a",
            "168f75633c0b4e4f89e70e01af552899"
          ]
        },
        "id": "98Z6EXnRJ-dS",
        "outputId": "0183d1a3-a9d3-47a3-dc6b-e464c8d62523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trenowanie modelu: Resnet56\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet56-187c023a.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet56-187c023a.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.39M/3.39M [00:00<00:00, 13.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "Miary dla: Resnet56:\n",
            "  Dokładność: 0.9437\n",
            "  Precyzja: 0.9436\n",
            "  Czułość: 0.9437\n",
            "  F1: 0.9436\n",
            "\n",
            "\n",
            "FGSM: \n",
            "\n",
            "  \n",
            "Miary dla: Resnet56:\n",
            "  Dokładność: 0.1512\n",
            "  Precyzja: 0.3280\n",
            "  Czułość: 0.1512\n",
            "  F1: 0.1035\n",
            "\n",
            "\n",
            "PGD: \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "PGD - Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfcdb1f9ad6e48bbbd93dac1e20b6632"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "Miary dla: Resnet56:\n",
            "  Dokładność: 0.0373\n",
            "  Precyzja: 0.0389\n",
            "  Czułość: 0.0373\n",
            "  F1: 0.0354\n",
            "\n",
            "\n",
            "BIM: \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "PGD - Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "156b6822152d4ae6a98fcf354c78a0e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \n",
            "Miary dla: Resnet56:\n",
            "  Dokładność: 0.1320\n",
            "  Precyzja: 0.1486\n",
            "  Czułość: 0.1320\n",
            "  F1: 0.1373\n",
            "\n",
            "\n",
            "JSMA: \n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "JSMA:   0%|          | 0/313 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15e2064bbd29499a91b3e3f8af7d27f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1884573942.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JSMA: \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mjacob_adver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSaliencyMapMethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mevaluate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjacob_adver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1884573942.py\u001b[0m in \u001b[0;36mattack\u001b[0;34m(x_test, attack_class, classifier, **kwargs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattack_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mattack_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0madversarial_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0madversarial_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/art/attacks/evasion/saliency_map.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mactive_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Compute saliency map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 feat_ind = self._saliency_map(\n\u001b[0m\u001b[1;32m    137\u001b[0m                     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactive_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactive_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/art/attacks/evasion/saliency_map.py\u001b[0m in \u001b[0;36m_saliency_map\u001b[0;34m(self, x, target, search_space)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0mcoefficients\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mmaximize\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mminimize\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msaliency\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \"\"\"\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nb_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/art/estimators/classification/pytorch.py\u001b[0m in \u001b[0;36mclass_gradient\u001b[0;34m(self, x, label, training_mode, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0munique_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                 torch.autograd.backward(\n\u001b[0m\u001b[1;32m    684\u001b[0m                     \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    830\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# Wrapper function for evasion attacks\n",
        "def attack(x_test, attack_class, classifier, **kwargs):\n",
        "    attack_instance = attack_class(classifier, **kwargs)\n",
        "    adversarial_examples = attack_instance.generate(x=x_test)\n",
        "    return adversarial_examples\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_metrics(classifier, x_test, y_test):\n",
        "  predictions = classifier.predict(x_test)\n",
        "  predicted_classes = np.argmax(predictions, axis=1)\n",
        "  accuracy = accuracy_score(y_test, predicted_classes)\n",
        "  precision = precision_score(y_test, predicted_classes, average='macro')\n",
        "  recall = recall_score(y_test, predicted_classes, average='macro')\n",
        "  f1 = f1_score(y_test, predicted_classes, average='macro')\n",
        "\n",
        "  print(f\"  \\nMiary dla: {model_name}:\")\n",
        "  print(f\"  Dokładność: {accuracy:.4f}\")\n",
        "  print(f\"  Precyzja: {precision:.4f}\")\n",
        "  print(f\"  Czułość: {recall:.4f}\")\n",
        "  print(f\"  F1: {f1:.4f}\")\n",
        "  print(f\"\\n\")\n",
        "\n",
        "\n",
        "for model_name,  model_fn in test_models.items():\n",
        "    print(f\"\\nTrenowanie modelu: {model_name}\")\n",
        "    model = model_fn()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    classifier = PyTorchClassifier(\n",
        "        model=model,\n",
        "        loss=loss_fn,\n",
        "        optimizer=optimizer,\n",
        "        input_shape=(3, 32, 32),\n",
        "        nb_classes=10,\n",
        "        clip_values=(min_, max_),\n",
        "        preprocessing = (mean, std)\n",
        "    )\n",
        "\n",
        "    evaluate_metrics(classifier, x_test, np.argmax(y_test, axis=1))\n",
        "    print(\"FGSM: \\n\")\n",
        "    fgsm_adver = attack(x_test, FastGradientMethod, classifier=classifier, eps=0.1, targeted=False)\n",
        "    evaluate_metrics(classifier, fgsm_adver, np.argmax(y_test, axis=1))\n",
        "\n",
        "    print(\"PGD: \\n\")\n",
        "    pgd_adver = attack(x_test, ProjectedGradientDescent, classifier=classifier, eps=0.1, eps_step=0.01, max_iter=40, targeted=False)\n",
        "    evaluate_metrics(classifier, pgd_adver, np.argmax(y_test, axis=1))\n",
        "\n",
        "    print(\"BIM: \\n\")\n",
        "    bim_adver = attack(x_test, BasicIterativeMethod, classifier=classifier, eps=0.01, eps_step=0.001, max_iter=10,\n",
        "batch_size=32,  targeted=False)\n",
        "    evaluate_metrics(classifier, bim_adver, np.argmax(y_test, axis=1))\n",
        "\n",
        "\n",
        "    print(\"JSMA: \\n\")\n",
        "    jacob_adver = attack(x_test, SaliencyMapMethod, classifier=classifier, theta=0.1, gamma=1, batch_size=32)\n",
        "    evaluate_metrics(classifier, jacob_adver, np.argmax(y_test, axis=1))\n"
      ]
    }
  ]
}
